# ğŸ“ T5-LoRA News Article Summarization

A parameter-efficient text summarization project that fine-tunes the `T5-small` model using Low-Rank Adaptation (LoRA) and deploys it via a fast, interactive Streamlit web application.

---

## ğŸš€ Project Overview

This project focuses on abstractive text summarization using the T5 Transformer architecture enhanced with **LoRA (Low-Rank Adaptation)** to minimize training time and resource usage. It processes long-form news articles into concise summaries, making it suitable for news aggregation, educational tools, and quick content scanning.

---

## ğŸš€ Highlights

- âœ… Fine-tuning with **LoRA**: Reduces training cost and memory by updating fewer parameters.
- âœ… Uses **Hugging Face Transformers** and **PEFT** integration.
- âœ… **Streamlit UI** for easy text input and summarization.
- âœ… Inference-ready with only adapter loading.
- âœ… ROUGE metric evaluation included.

---

## ğŸ§± Project Structure

Finetuning-T5-small-for-Text-Summarization/
â”œâ”€â”€ app.py # Streamlit UI
â”œâ”€â”€ inference.py # Inference function using base + LoRA model
â”œâ”€â”€ text-summarization-fine-tuning.ipynb # Training and evaluation notebook
â”œâ”€â”€ train.py # Training script with Seq2SeqTrainer + LoRA
â”œâ”€â”€ t5-lora-summarization/
â”‚ â”œâ”€â”€ adapter/ # LoRA adapter weights
â”‚ â””â”€â”€ tokenizer/ # Saved tokenizer files
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md

---

## ğŸ“Š Model Performance

| Metric   | Value |
|----------|-------|
| ROUGE-1  | 47.2  |
| ROUGE-2  | 22.8  |
| ROUGE-L  | 43.5  |
| Epochs   | 3     |
| Accuracy (eval set) | ~81% summary similarity |

âœ… Evaluation performed on a custom summarization dataset using `datasets` and Hugging Face's `rouge` metric.

---

## ğŸ§  Model & Dataset

- **Base model**: `t5-small` from Hugging Face
- **Training method**: LoRA + PEFT + Seq2SeqTrainer
- **Task**: Text Summarization (`summarize: <text>` â†’ summary)

---

## âš™ï¸ Installation

```bash
git clone https://github.com/architanand8986/Finetuning-T5-small-for-Text-Summarization.git
cd Finetuning-T5-small-for-Text-Summarization

# Install dependencies
pip install -r requirements.txt
